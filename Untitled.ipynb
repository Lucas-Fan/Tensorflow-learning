{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.set_random_seed(1)\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Hyper Parameters\n",
    "BATCH_SIZE = 64\n",
    "TIME_STEP = 28          # rnn time step / image height\n",
    "INPUT_SIZE = 28         # rnn input size / image width\n",
    "LR = 0.01               # learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)              # they has been normalized to range (0,1)\n",
    "test_x = mnist.test.images[:2000]\n",
    "test_y = mnist.test.labels[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 784)\n",
      "(55000, 10)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAEICAYAAACQ6CLfAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqf8FpJjIO4nxTlkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f314929f110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot one example\n",
    "print(mnist.train.images.shape)     # (55000, 28 * 28)\n",
    "print(mnist.train.labels.shape)   # (55000, 10)\n",
    "plt.imshow(mnist.train.images[0].reshape((28, 28)), cmap='gray')\n",
    "plt.title('%i' % np.argmax(mnist.train.labels[0]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tensorflow placeholders\n",
    "tf_x = tf.placeholder(tf.float32, [None, TIME_STEP * INPUT_SIZE])       # shape(batch, 784)\n",
    "image = tf.reshape(tf_x, [-1, TIME_STEP, INPUT_SIZE])                   # (batch, height, width, channel)\n",
    "tf_y = tf.placeholder(tf.int32, [None, 10])                             # input y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RNN\n",
    "rnn_cell = tf.contrib.rnn.BasicLSTMCell(num_units=64)\n",
    "outputs, (h_c, h_n) = tf.nn.dynamic_rnn(\n",
    "    rnn_cell,                   # cell you have chosen\n",
    "    image,                      # input\n",
    "    initial_state=None,         # the initial hidden state\n",
    "    dtype=tf.float32,           # must given if set initial_state = None\n",
    "    time_major=False,           # False: (batch, time step, input); True: (time step, batch, input)\n",
    ")\n",
    "output = tf.layers.dense(outputs[:, -1, :], 10)              # output based on the last output step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.losses.softmax_cross_entropy(onehot_labels=tf_y, logits=output)           # compute cost\n",
    "train_op = tf.train.AdamOptimizer(LR).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = tf.metrics.accuracy(          # return (acc, update_op), and create 2 local variables\n",
    "    labels=tf.argmax(tf_y, axis=1), predictions=tf.argmax(output, axis=1),)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "init_op = tf.group(tf.global_variables_initializer(), tf.local_variables_initializer()) # the local var is for accuracy_op\n",
    "sess.run(init_op)     # initialize var in graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('train loss: 2.3040', '| test accuracy: 0.13')\n",
      "('train loss: 0.8905', '| test accuracy: 0.41')\n",
      "('train loss: 0.6218', '| test accuracy: 0.52')\n",
      "('train loss: 0.4758', '| test accuracy: 0.60')\n",
      "('train loss: 0.4436', '| test accuracy: 0.65')\n",
      "('train loss: 0.2367', '| test accuracy: 0.69')\n",
      "('train loss: 0.2158', '| test accuracy: 0.73')\n",
      "('train loss: 0.1946', '| test accuracy: 0.75')\n",
      "('train loss: 0.2070', '| test accuracy: 0.77')\n",
      "('train loss: 0.3919', '| test accuracy: 0.79')\n",
      "('train loss: 0.1161', '| test accuracy: 0.80')\n",
      "('train loss: 0.2584', '| test accuracy: 0.81')\n",
      "('train loss: 0.1280', '| test accuracy: 0.82')\n",
      "('train loss: 0.1100', '| test accuracy: 0.83')\n",
      "('train loss: 0.1354', '| test accuracy: 0.84')\n",
      "('train loss: 0.2086', '| test accuracy: 0.84')\n",
      "('train loss: 0.0435', '| test accuracy: 0.85')\n",
      "('train loss: 0.2685', '| test accuracy: 0.86')\n",
      "('train loss: 0.2933', '| test accuracy: 0.86')\n",
      "('train loss: 0.0330', '| test accuracy: 0.87')\n",
      "('train loss: 0.0535', '| test accuracy: 0.87')\n",
      "('train loss: 0.1177', '| test accuracy: 0.87')\n",
      "('train loss: 0.2083', '| test accuracy: 0.88')\n",
      "('train loss: 0.1120', '| test accuracy: 0.88')\n"
     ]
    }
   ],
   "source": [
    "for step in range(1200):    # training\n",
    "    b_x, b_y = mnist.train.next_batch(BATCH_SIZE)\n",
    "    _, loss_ = sess.run([train_op, loss], {tf_x: b_x, tf_y: b_y})\n",
    "    if step % 50 == 0:      # testing\n",
    "        accuracy_ = sess.run(accuracy, {tf_x: test_x, tf_y: test_y})\n",
    "        print('train loss: %.4f' % loss_, '| test accuracy: %.2f' % accuracy_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([7, 2, 1, 0, 4, 1, 4, 9, 5, 9]), 'prediction number')\n",
      "(array([7, 2, 1, 0, 4, 1, 4, 9, 5, 9]), 'real number')\n"
     ]
    }
   ],
   "source": [
    "# print 10 predictions from test data\n",
    "test_output = sess.run(output, {tf_x: test_x[:10]})\n",
    "pred_y = np.argmax(test_output, 1)\n",
    "print(pred_y, 'prediction number')\n",
    "print(np.argmax(test_y[:10], 1), 'real number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
